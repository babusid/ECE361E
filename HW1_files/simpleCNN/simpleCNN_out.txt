Epoch: [1/25], Step: [100/468], Loss: 0.5498 Acc: 82.93%
Epoch: [1/25], Step: [200/468], Loss: 0.3463 Acc: 89.34%
Epoch: [1/25], Step: [300/468], Loss: 0.2670 Acc: 91.87%
Epoch: [1/25], Step: [400/468], Loss: 0.2244 Acc: 93.15%
Test accuracy: 98.18 % Test loss: 0.0578
Epoch: [2/25], Step: [100/468], Loss: 0.0688 Acc: 97.84%
Epoch: [2/25], Step: [200/468], Loss: 0.0664 Acc: 97.93%
Epoch: [2/25], Step: [300/468], Loss: 0.0665 Acc: 97.95%
Epoch: [2/25], Step: [400/468], Loss: 0.0657 Acc: 98.01%
Test accuracy: 98.50 % Test loss: 0.0463
Epoch: [3/25], Step: [100/468], Loss: 0.0514 Acc: 98.34%
Epoch: [3/25], Step: [200/468], Loss: 0.0511 Acc: 98.44%
Epoch: [3/25], Step: [300/468], Loss: 0.0517 Acc: 98.46%
Epoch: [3/25], Step: [400/468], Loss: 0.0497 Acc: 98.52%
Test accuracy: 98.62 % Test loss: 0.0419
Epoch: [4/25], Step: [100/468], Loss: 0.0430 Acc: 98.61%
Epoch: [4/25], Step: [200/468], Loss: 0.0430 Acc: 98.65%
Epoch: [4/25], Step: [300/468], Loss: 0.0431 Acc: 98.65%
Epoch: [4/25], Step: [400/468], Loss: 0.0430 Acc: 98.66%
Test accuracy: 98.76 % Test loss: 0.0375
Epoch: [5/25], Step: [100/468], Loss: 0.0329 Acc: 98.98%
Epoch: [5/25], Step: [200/468], Loss: 0.0358 Acc: 98.85%
Epoch: [5/25], Step: [300/468], Loss: 0.0364 Acc: 98.84%
Epoch: [5/25], Step: [400/468], Loss: 0.0356 Acc: 98.90%
Test accuracy: 98.83 % Test loss: 0.0342
Epoch: [6/25], Step: [100/468], Loss: 0.0294 Acc: 99.17%
Epoch: [6/25], Step: [200/468], Loss: 0.0312 Acc: 99.08%
Epoch: [6/25], Step: [300/468], Loss: 0.0313 Acc: 99.04%
Epoch: [6/25], Step: [400/468], Loss: 0.0318 Acc: 99.03%
Test accuracy: 98.86 % Test loss: 0.0350
Epoch: [7/25], Step: [100/468], Loss: 0.0265 Acc: 99.16%
Epoch: [7/25], Step: [200/468], Loss: 0.0290 Acc: 99.12%
Epoch: [7/25], Step: [300/468], Loss: 0.0280 Acc: 99.15%
Epoch: [7/25], Step: [400/468], Loss: 0.0276 Acc: 99.14%
Test accuracy: 98.85 % Test loss: 0.0359
Epoch: [8/25], Step: [100/468], Loss: 0.0234 Acc: 99.29%
Epoch: [8/25], Step: [200/468], Loss: 0.0243 Acc: 99.25%
Epoch: [8/25], Step: [300/468], Loss: 0.0266 Acc: 99.19%
Epoch: [8/25], Step: [400/468], Loss: 0.0255 Acc: 99.21%
Test accuracy: 99.01 % Test loss: 0.0298
Epoch: [9/25], Step: [100/468], Loss: 0.0221 Acc: 99.23%
Epoch: [9/25], Step: [200/468], Loss: 0.0220 Acc: 99.29%
Epoch: [9/25], Step: [300/468], Loss: 0.0232 Acc: 99.29%
Epoch: [9/25], Step: [400/468], Loss: 0.0229 Acc: 99.29%
Test accuracy: 98.75 % Test loss: 0.0370
Epoch: [10/25], Step: [100/468], Loss: 0.0197 Acc: 99.38%
Epoch: [10/25], Step: [200/468], Loss: 0.0197 Acc: 99.37%
Epoch: [10/25], Step: [300/468], Loss: 0.0203 Acc: 99.36%
Epoch: [10/25], Step: [400/468], Loss: 0.0209 Acc: 99.36%
Test accuracy: 98.94 % Test loss: 0.0332
Epoch: [11/25], Step: [100/468], Loss: 0.0165 Acc: 99.54%
Epoch: [11/25], Step: [200/468], Loss: 0.0165 Acc: 99.54%
Epoch: [11/25], Step: [300/468], Loss: 0.0168 Acc: 99.49%
Epoch: [11/25], Step: [400/468], Loss: 0.0169 Acc: 99.50%
Test accuracy: 98.84 % Test loss: 0.0349
Epoch: [12/25], Step: [100/468], Loss: 0.0167 Acc: 99.52%
Epoch: [12/25], Step: [200/468], Loss: 0.0166 Acc: 99.49%
Epoch: [12/25], Step: [300/468], Loss: 0.0175 Acc: 99.46%
Epoch: [12/25], Step: [400/468], Loss: 0.0174 Acc: 99.46%
Test accuracy: 99.10 % Test loss: 0.0287
Epoch: [13/25], Step: [100/468], Loss: 0.0170 Acc: 99.52%
Epoch: [13/25], Step: [200/468], Loss: 0.0159 Acc: 99.52%
Epoch: [13/25], Step: [300/468], Loss: 0.0153 Acc: 99.55%
Epoch: [13/25], Step: [400/468], Loss: 0.0157 Acc: 99.52%
Test accuracy: 99.07 % Test loss: 0.0298
Epoch: [14/25], Step: [100/468], Loss: 0.0148 Acc: 99.60%
Epoch: [14/25], Step: [200/468], Loss: 0.0130 Acc: 99.64%
Epoch: [14/25], Step: [300/468], Loss: 0.0136 Acc: 99.61%
Epoch: [14/25], Step: [400/468], Loss: 0.0139 Acc: 99.59%
Test accuracy: 98.88 % Test loss: 0.0398
Epoch: [15/25], Step: [100/468], Loss: 0.0096 Acc: 99.76%
Epoch: [15/25], Step: [200/468], Loss: 0.0105 Acc: 99.73%
Epoch: [15/25], Step: [300/468], Loss: 0.0110 Acc: 99.72%
Epoch: [15/25], Step: [400/468], Loss: 0.0118 Acc: 99.67%
Test accuracy: 99.13 % Test loss: 0.0313
Epoch: [16/25], Step: [100/468], Loss: 0.0105 Acc: 99.72%
Epoch: [16/25], Step: [200/468], Loss: 0.0112 Acc: 99.72%
Epoch: [16/25], Step: [300/468], Loss: 0.0115 Acc: 99.67%
Epoch: [16/25], Step: [400/468], Loss: 0.0111 Acc: 99.69%
Test accuracy: 98.99 % Test loss: 0.0351
Epoch: [17/25], Step: [100/468], Loss: 0.0082 Acc: 99.79%
Epoch: [17/25], Step: [200/468], Loss: 0.0080 Acc: 99.80%
Epoch: [17/25], Step: [300/468], Loss: 0.0088 Acc: 99.78%
Epoch: [17/25], Step: [400/468], Loss: 0.0100 Acc: 99.72%
Test accuracy: 98.97 % Test loss: 0.0368
Epoch: [18/25], Step: [100/468], Loss: 0.0087 Acc: 99.78%
Epoch: [18/25], Step: [200/468], Loss: 0.0079 Acc: 99.83%
Epoch: [18/25], Step: [300/468], Loss: 0.0081 Acc: 99.83%
Epoch: [18/25], Step: [400/468], Loss: 0.0087 Acc: 99.78%
Test accuracy: 98.95 % Test loss: 0.0357
Epoch: [19/25], Step: [100/468], Loss: 0.0094 Acc: 99.74%
Epoch: [19/25], Step: [200/468], Loss: 0.0080 Acc: 99.78%
Epoch: [19/25], Step: [300/468], Loss: 0.0084 Acc: 99.76%
Epoch: [19/25], Step: [400/468], Loss: 0.0078 Acc: 99.78%
Test accuracy: 99.08 % Test loss: 0.0319
Epoch: [20/25], Step: [100/468], Loss: 0.0090 Acc: 99.77%
Epoch: [20/25], Step: [200/468], Loss: 0.0075 Acc: 99.81%
Epoch: [20/25], Step: [300/468], Loss: 0.0071 Acc: 99.82%
Epoch: [20/25], Step: [400/468], Loss: 0.0071 Acc: 99.82%
Test accuracy: 99.03 % Test loss: 0.0356
Epoch: [21/25], Step: [100/468], Loss: 0.0057 Acc: 99.88%
Epoch: [21/25], Step: [200/468], Loss: 0.0061 Acc: 99.85%
Epoch: [21/25], Step: [300/468], Loss: 0.0062 Acc: 99.84%
Epoch: [21/25], Step: [400/468], Loss: 0.0068 Acc: 99.83%
Test accuracy: 99.08 % Test loss: 0.0339
Epoch: [22/25], Step: [100/468], Loss: 0.0051 Acc: 99.88%
Epoch: [22/25], Step: [200/468], Loss: 0.0047 Acc: 99.89%
Epoch: [22/25], Step: [300/468], Loss: 0.0054 Acc: 99.84%
Epoch: [22/25], Step: [400/468], Loss: 0.0057 Acc: 99.84%
Test accuracy: 99.08 % Test loss: 0.0352
Epoch: [23/25], Step: [100/468], Loss: 0.0063 Acc: 99.86%
Epoch: [23/25], Step: [200/468], Loss: 0.0052 Acc: 99.88%
Epoch: [23/25], Step: [300/468], Loss: 0.0052 Acc: 99.87%
Epoch: [23/25], Step: [400/468], Loss: 0.0053 Acc: 99.86%
Test accuracy: 99.02 % Test loss: 0.0371
Epoch: [24/25], Step: [100/468], Loss: 0.0040 Acc: 99.91%
Epoch: [24/25], Step: [200/468], Loss: 0.0037 Acc: 99.93%
Epoch: [24/25], Step: [300/468], Loss: 0.0046 Acc: 99.89%
Epoch: [24/25], Step: [400/468], Loss: 0.0046 Acc: 99.88%
Test accuracy: 99.06 % Test loss: 0.0367
Epoch: [25/25], Step: [100/468], Loss: 0.0023 Acc: 99.98%
Epoch: [25/25], Step: [200/468], Loss: 0.0027 Acc: 99.96%
Epoch: [25/25], Step: [300/468], Loss: 0.0030 Acc: 99.95%
Epoch: [25/25], Step: [400/468], Loss: 0.0037 Acc: 99.93%
Test accuracy: 98.98 % Test loss: 0.0380
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleCNN                                [1, 10]                   --
├─Conv2d: 1-1                            [1, 32, 28, 28]           320
├─MaxPool2d: 1-2                         [1, 32, 14, 14]           --
├─Conv2d: 1-3                            [1, 64, 14, 14]           18,496
├─MaxPool2d: 1-4                         [1, 64, 7, 7]             --
├─Linear: 1-5                            [1, 10]                   31,370
==========================================================================================
Total params: 50,186
Trainable params: 50,186
Non-trainable params: 0
Total mult-adds (M): 3.91
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.30
Params size (MB): 0.20
Estimated Total Size (MB): 0.51
==========================================================================================
Saved Model size on disk: 197 kb
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 3869824
FLOPs: 7739648
