Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 32, 32, 32)        864       
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 32)        128       
_________________________________________________________________
activation (Activation)      (None, 32, 32, 32)        0         
_________________________________________________________________
depthwise_conv2d (DepthwiseC (None, 32, 32, 32)        288       
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 64)        2048      
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
depthwise_conv2d_1 (Depthwis (None, 16, 16, 64)        576       
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 128)       8192      
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
depthwise_conv2d_2 (Depthwis (None, 16, 16, 128)       1152      
_________________________________________________________________
batch_normalization_5 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_5 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 128)       16384     
_________________________________________________________________
batch_normalization_6 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_6 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
depthwise_conv2d_3 (Depthwis (None, 8, 8, 128)         1152      
_________________________________________________________________
batch_normalization_7 (Batch (None, 8, 8, 128)         512       
_________________________________________________________________
activation_7 (Activation)    (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 256)         32768     
_________________________________________________________________
batch_normalization_8 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_8 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
depthwise_conv2d_4 (Depthwis (None, 8, 8, 256)         2304      
_________________________________________________________________
batch_normalization_9 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_9 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 256)         65536     
_________________________________________________________________
batch_normalization_10 (Batc (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_10 (Activation)   (None, 8, 8, 256)         0         
_________________________________________________________________
depthwise_conv2d_5 (Depthwis (None, 4, 4, 256)         2304      
_________________________________________________________________
batch_normalization_11 (Batc (None, 4, 4, 256)         1024      
_________________________________________________________________
activation_11 (Activation)   (None, 4, 4, 256)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 512)         131072    
_________________________________________________________________
batch_normalization_12 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_12 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_6 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_13 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_13 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_14 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_14 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_7 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_15 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_15 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_16 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_16 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_8 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_17 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_17 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_18 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_18 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_9 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_19 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_19 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_20 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_20 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_10 (Depthwi (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_21 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_21 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_22 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_22 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_11 (Depthwi (None, 2, 2, 512)         4608      
_________________________________________________________________
batch_normalization_23 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
activation_23 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 2, 2, 1024)        524288    
_________________________________________________________________
batch_normalization_24 (Batc (None, 2, 2, 1024)        4096      
_________________________________________________________________
activation_24 (Activation)   (None, 2, 2, 1024)        0         
_________________________________________________________________
depthwise_conv2d_12 (Depthwi (None, 2, 2, 1024)        9216      
_________________________________________________________________
batch_normalization_25 (Batc (None, 2, 2, 1024)        4096      
_________________________________________________________________
activation_25 (Activation)   (None, 2, 2, 1024)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 2, 2, 1024)        1048576   
_________________________________________________________________
batch_normalization_26 (Batc (None, 2, 2, 1024)        4096      
_________________________________________________________________
activation_26 (Activation)   (None, 2, 2, 1024)        0         
_________________________________________________________________
avg_pool (AveragePooling2D)  (None, 1, 1, 1024)        0         
_________________________________________________________________
flatten (Flatten)            (None, 1024)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                10250     
_________________________________________________________________
activation_27 (Activation)   (None, 10)                0         
=================================================================
Total params: 3,239,114
Trainable params: 3,217,226
Non-trainable params: 21,888
_________________________________________________________________
Epoch 1/100
391/391 - 23s - loss: 1.7858 - accuracy: 0.3401
Epoch 2/100
391/391 - 11s - loss: 1.3124 - accuracy: 0.5251
Epoch 3/100
391/391 - 11s - loss: 1.0917 - accuracy: 0.6112
Epoch 4/100
391/391 - 11s - loss: 0.9239 - accuracy: 0.6707
Epoch 5/100
391/391 - 11s - loss: 0.8001 - accuracy: 0.7183
Epoch 6/100
391/391 - 11s - loss: 0.7023 - accuracy: 0.7549
Epoch 7/100
391/391 - 11s - loss: 0.6161 - accuracy: 0.7828
Epoch 8/100
391/391 - 11s - loss: 0.5420 - accuracy: 0.8109
Epoch 9/100
391/391 - 11s - loss: 0.4751 - accuracy: 0.8344
Epoch 10/100
391/391 - 11s - loss: 0.4183 - accuracy: 0.8536
Epoch 11/100
391/391 - 11s - loss: 0.3649 - accuracy: 0.8734
Epoch 12/100
391/391 - 11s - loss: 0.3269 - accuracy: 0.8850
Epoch 13/100
391/391 - 11s - loss: 0.2874 - accuracy: 0.8990
Epoch 14/100
391/391 - 11s - loss: 0.2557 - accuracy: 0.9102
Epoch 15/100
391/391 - 11s - loss: 0.2264 - accuracy: 0.9205
Epoch 16/100
391/391 - 11s - loss: 0.2028 - accuracy: 0.9283
Epoch 17/100
391/391 - 11s - loss: 0.1879 - accuracy: 0.9348
Epoch 18/100
391/391 - 11s - loss: 0.1715 - accuracy: 0.9392
Epoch 19/100
391/391 - 11s - loss: 0.1556 - accuracy: 0.9455
Epoch 20/100
391/391 - 11s - loss: 0.1456 - accuracy: 0.9488
Epoch 21/100
391/391 - 11s - loss: 0.1336 - accuracy: 0.9529
Epoch 22/100
391/391 - 11s - loss: 0.1244 - accuracy: 0.9568
Epoch 23/100
391/391 - 11s - loss: 0.1206 - accuracy: 0.9581
Epoch 24/100
391/391 - 11s - loss: 0.1167 - accuracy: 0.9592
Epoch 25/100
391/391 - 11s - loss: 0.1009 - accuracy: 0.9643
Epoch 26/100
391/391 - 11s - loss: 0.1028 - accuracy: 0.9645
Epoch 27/100
391/391 - 11s - loss: 0.0970 - accuracy: 0.9662
Epoch 28/100
391/391 - 11s - loss: 0.0869 - accuracy: 0.9696
Epoch 29/100
391/391 - 11s - loss: 0.0907 - accuracy: 0.9680
Epoch 30/100
391/391 - 11s - loss: 0.0838 - accuracy: 0.9696
Epoch 31/100
391/391 - 11s - loss: 0.0786 - accuracy: 0.9727
Epoch 32/100
391/391 - 11s - loss: 0.0818 - accuracy: 0.9710
Epoch 33/100
391/391 - 11s - loss: 0.0688 - accuracy: 0.9760
Epoch 34/100
391/391 - 11s - loss: 0.0721 - accuracy: 0.9744
Epoch 35/100
391/391 - 11s - loss: 0.0698 - accuracy: 0.9765
Epoch 36/100
391/391 - 11s - loss: 0.0695 - accuracy: 0.9761
Epoch 37/100
391/391 - 11s - loss: 0.0639 - accuracy: 0.9782
Epoch 38/100
391/391 - 11s - loss: 0.0631 - accuracy: 0.9784
Epoch 39/100
391/391 - 11s - loss: 0.0584 - accuracy: 0.9802
Epoch 40/100
391/391 - 11s - loss: 0.0607 - accuracy: 0.9784
Epoch 41/100
391/391 - 11s - loss: 0.0583 - accuracy: 0.9800
Epoch 42/100
391/391 - 11s - loss: 0.0550 - accuracy: 0.9809
Epoch 43/100
391/391 - 11s - loss: 0.0545 - accuracy: 0.9813
Epoch 44/100
391/391 - 11s - loss: 0.0516 - accuracy: 0.9825
Epoch 45/100
391/391 - 11s - loss: 0.0519 - accuracy: 0.9822
Epoch 46/100
391/391 - 11s - loss: 0.0514 - accuracy: 0.9822
Epoch 47/100
391/391 - 11s - loss: 0.0509 - accuracy: 0.9821
Epoch 48/100
391/391 - 11s - loss: 0.0466 - accuracy: 0.9836
Epoch 49/100
391/391 - 11s - loss: 0.0442 - accuracy: 0.9850
Epoch 50/100
391/391 - 11s - loss: 0.0507 - accuracy: 0.9821
Epoch 51/100
391/391 - 11s - loss: 0.0434 - accuracy: 0.9853
Epoch 52/100
391/391 - 11s - loss: 0.0417 - accuracy: 0.9860
Epoch 53/100
391/391 - 11s - loss: 0.0443 - accuracy: 0.9846
Epoch 54/100
391/391 - 11s - loss: 0.0382 - accuracy: 0.9871
Epoch 55/100
391/391 - 11s - loss: 0.0416 - accuracy: 0.9853
Epoch 56/100
391/391 - 11s - loss: 0.0383 - accuracy: 0.9869
Epoch 57/100
391/391 - 11s - loss: 0.0407 - accuracy: 0.9865
Epoch 58/100
391/391 - 11s - loss: 0.0383 - accuracy: 0.9868
Epoch 59/100
391/391 - 11s - loss: 0.0351 - accuracy: 0.9883
Epoch 60/100
391/391 - 11s - loss: 0.0357 - accuracy: 0.9880
Epoch 61/100
391/391 - 11s - loss: 0.0380 - accuracy: 0.9863
Epoch 62/100
391/391 - 11s - loss: 0.0357 - accuracy: 0.9874
Epoch 63/100
391/391 - 11s - loss: 0.0336 - accuracy: 0.9889
Epoch 64/100
391/391 - 11s - loss: 0.0311 - accuracy: 0.9892
Epoch 65/100
391/391 - 11s - loss: 0.0332 - accuracy: 0.9889
Epoch 66/100
391/391 - 11s - loss: 0.0365 - accuracy: 0.9875
Epoch 67/100
391/391 - 11s - loss: 0.0320 - accuracy: 0.9890
Epoch 68/100
391/391 - 11s - loss: 0.0310 - accuracy: 0.9891
Epoch 69/100
391/391 - 11s - loss: 0.0283 - accuracy: 0.9907
Epoch 70/100
391/391 - 11s - loss: 0.0310 - accuracy: 0.9891
Epoch 71/100
391/391 - 11s - loss: 0.0323 - accuracy: 0.9890
Epoch 72/100
391/391 - 11s - loss: 0.0279 - accuracy: 0.9903
Epoch 73/100
391/391 - 11s - loss: 0.0292 - accuracy: 0.9901
Epoch 74/100
391/391 - 11s - loss: 0.0266 - accuracy: 0.9908
Epoch 75/100
391/391 - 11s - loss: 0.0289 - accuracy: 0.9902
Epoch 76/100
391/391 - 11s - loss: 0.0270 - accuracy: 0.9906
Epoch 77/100
391/391 - 11s - loss: 0.0284 - accuracy: 0.9909
Epoch 78/100
391/391 - 11s - loss: 0.0272 - accuracy: 0.9906
Epoch 79/100
391/391 - 11s - loss: 0.0271 - accuracy: 0.9910
Epoch 80/100
391/391 - 11s - loss: 0.0277 - accuracy: 0.9906
Epoch 81/100
391/391 - 11s - loss: 0.0238 - accuracy: 0.9916
Epoch 82/100
391/391 - 11s - loss: 0.0282 - accuracy: 0.9903
Epoch 83/100
391/391 - 11s - loss: 0.0235 - accuracy: 0.9916
Epoch 84/100
391/391 - 11s - loss: 0.0240 - accuracy: 0.9918
Epoch 85/100
391/391 - 11s - loss: 0.0232 - accuracy: 0.9921
Epoch 86/100
391/391 - 11s - loss: 0.0251 - accuracy: 0.9913
Epoch 87/100
391/391 - 11s - loss: 0.0262 - accuracy: 0.9911
Epoch 88/100
391/391 - 11s - loss: 0.0214 - accuracy: 0.9927
Epoch 89/100
391/391 - 11s - loss: 0.0222 - accuracy: 0.9922
Epoch 90/100
391/391 - 11s - loss: 0.0203 - accuracy: 0.9933
Epoch 91/100
391/391 - 11s - loss: 0.0242 - accuracy: 0.9917
Epoch 92/100
391/391 - 11s - loss: 0.0234 - accuracy: 0.9921
Epoch 93/100
391/391 - 11s - loss: 0.0247 - accuracy: 0.9915
Epoch 94/100
391/391 - 11s - loss: 0.0188 - accuracy: 0.9935
Epoch 95/100
391/391 - 11s - loss: 0.0220 - accuracy: 0.9927
Epoch 96/100
391/391 - 11s - loss: 0.0184 - accuracy: 0.9937
Epoch 97/100
391/391 - 11s - loss: 0.0240 - accuracy: 0.9912
Epoch 98/100
391/391 - 11s - loss: 0.0215 - accuracy: 0.9926
Epoch 99/100
391/391 - 11s - loss: 0.0200 - accuracy: 0.9933
Epoch 100/100
391/391 - 11s - loss: 0.0171 - accuracy: 0.9943
INFO: Training Time: 1097.319 seconds
79/79 - 1s - loss: 1.3048 - accuracy: 0.7922
INFO: Test Loss: 1.3048455715179443
INFO: Test Accuracy: 0.7922000288963318
