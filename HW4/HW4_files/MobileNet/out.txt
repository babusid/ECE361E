Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 32, 32, 32)        864       
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 32)        128       
_________________________________________________________________
activation (Activation)      (None, 32, 32, 32)        0         
_________________________________________________________________
depthwise_conv2d (DepthwiseC (None, 32, 32, 32)        288       
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 64)        2048      
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
depthwise_conv2d_1 (Depthwis (None, 16, 16, 64)        576       
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 128)       8192      
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
depthwise_conv2d_2 (Depthwis (None, 16, 16, 128)       1152      
_________________________________________________________________
batch_normalization_5 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_5 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 128)       16384     
_________________________________________________________________
batch_normalization_6 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_6 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
depthwise_conv2d_3 (Depthwis (None, 8, 8, 128)         1152      
_________________________________________________________________
batch_normalization_7 (Batch (None, 8, 8, 128)         512       
_________________________________________________________________
activation_7 (Activation)    (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 256)         32768     
_________________________________________________________________
batch_normalization_8 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_8 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
depthwise_conv2d_4 (Depthwis (None, 8, 8, 256)         2304      
_________________________________________________________________
batch_normalization_9 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_9 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 256)         65536     
_________________________________________________________________
batch_normalization_10 (Batc (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_10 (Activation)   (None, 8, 8, 256)         0         
_________________________________________________________________
depthwise_conv2d_5 (Depthwis (None, 4, 4, 256)         2304      
_________________________________________________________________
batch_normalization_11 (Batc (None, 4, 4, 256)         1024      
_________________________________________________________________
activation_11 (Activation)   (None, 4, 4, 256)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 512)         131072    
_________________________________________________________________
batch_normalization_12 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_12 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_6 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_13 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_13 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_14 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_14 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_7 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_15 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_15 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_16 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_16 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_8 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_17 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_17 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_18 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_18 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_9 (Depthwis (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_19 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_19 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_20 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_20 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_10 (Depthwi (None, 4, 4, 512)         4608      
_________________________________________________________________
batch_normalization_21 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_21 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 4, 4, 512)         262144    
_________________________________________________________________
batch_normalization_22 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
activation_22 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
depthwise_conv2d_11 (Depthwi (None, 2, 2, 512)         4608      
_________________________________________________________________
batch_normalization_23 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
activation_23 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 2, 2, 1024)        524288    
_________________________________________________________________
batch_normalization_24 (Batc (None, 2, 2, 1024)        4096      
_________________________________________________________________
activation_24 (Activation)   (None, 2, 2, 1024)        0         
_________________________________________________________________
depthwise_conv2d_12 (Depthwi (None, 2, 2, 1024)        9216      
_________________________________________________________________
batch_normalization_25 (Batc (None, 2, 2, 1024)        4096      
_________________________________________________________________
activation_25 (Activation)   (None, 2, 2, 1024)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 2, 2, 1024)        1048576   
_________________________________________________________________
batch_normalization_26 (Batc (None, 2, 2, 1024)        4096      
_________________________________________________________________
activation_26 (Activation)   (None, 2, 2, 1024)        0         
_________________________________________________________________
avg_pool (AveragePooling2D)  (None, 1, 1, 1024)        0         
_________________________________________________________________
flatten (Flatten)            (None, 1024)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                10250     
_________________________________________________________________
activation_27 (Activation)   (None, 10)                0         
=================================================================
Total params: 3,239,114
Trainable params: 3,217,226
Non-trainable params: 21,888
_________________________________________________________________
Epoch 1/100
391/391 - 24s - loss: 1.7695 - accuracy: 0.3470 - val_loss: 1.4511 - val_accuracy: 0.4676
Epoch 2/100
391/391 - 12s - loss: 1.3144 - accuracy: 0.5213 - val_loss: 1.2290 - val_accuracy: 0.5554
Epoch 3/100
391/391 - 12s - loss: 1.0969 - accuracy: 0.6060 - val_loss: 1.1443 - val_accuracy: 0.5994
Epoch 4/100
391/391 - 12s - loss: 0.9245 - accuracy: 0.6725 - val_loss: 0.9730 - val_accuracy: 0.6535
Epoch 5/100
391/391 - 12s - loss: 0.7940 - accuracy: 0.7189 - val_loss: 0.9012 - val_accuracy: 0.6817
Epoch 6/100
391/391 - 12s - loss: 0.6835 - accuracy: 0.7608 - val_loss: 0.8408 - val_accuracy: 0.7101
Epoch 7/100
391/391 - 12s - loss: 0.5957 - accuracy: 0.7914 - val_loss: 0.8160 - val_accuracy: 0.7186
Epoch 8/100
391/391 - 12s - loss: 0.5249 - accuracy: 0.8149 - val_loss: 0.8293 - val_accuracy: 0.7275
Epoch 9/100
391/391 - 12s - loss: 0.4666 - accuracy: 0.8356 - val_loss: 0.8256 - val_accuracy: 0.7272
Epoch 10/100
391/391 - 12s - loss: 0.4116 - accuracy: 0.8558 - val_loss: 0.8419 - val_accuracy: 0.7297
Epoch 11/100
391/391 - 12s - loss: 0.3607 - accuracy: 0.8729 - val_loss: 0.7927 - val_accuracy: 0.7564
Epoch 12/100
391/391 - 12s - loss: 0.3150 - accuracy: 0.8892 - val_loss: 0.8511 - val_accuracy: 0.7518
Epoch 13/100
391/391 - 12s - loss: 0.2841 - accuracy: 0.8995 - val_loss: 0.8552 - val_accuracy: 0.7521
Epoch 14/100
391/391 - 12s - loss: 0.2549 - accuracy: 0.9110 - val_loss: 0.8424 - val_accuracy: 0.7516
Epoch 15/100
391/391 - 12s - loss: 0.2181 - accuracy: 0.9232 - val_loss: 0.8849 - val_accuracy: 0.7613
Epoch 16/100
391/391 - 12s - loss: 0.2007 - accuracy: 0.9303 - val_loss: 0.9403 - val_accuracy: 0.7545
Epoch 17/100
391/391 - 12s - loss: 0.1767 - accuracy: 0.9386 - val_loss: 0.9301 - val_accuracy: 0.7586
Epoch 18/100
391/391 - 12s - loss: 0.1614 - accuracy: 0.9433 - val_loss: 0.9462 - val_accuracy: 0.7629
Epoch 19/100
391/391 - 12s - loss: 0.1506 - accuracy: 0.9469 - val_loss: 0.9826 - val_accuracy: 0.7650
Epoch 20/100
391/391 - 12s - loss: 0.1391 - accuracy: 0.9512 - val_loss: 0.8999 - val_accuracy: 0.7726
Epoch 21/100
391/391 - 12s - loss: 0.1314 - accuracy: 0.9540 - val_loss: 0.9390 - val_accuracy: 0.7639
Epoch 22/100
391/391 - 12s - loss: 0.1193 - accuracy: 0.9582 - val_loss: 1.0341 - val_accuracy: 0.7648
Epoch 23/100
391/391 - 12s - loss: 0.1170 - accuracy: 0.9596 - val_loss: 0.9612 - val_accuracy: 0.7730
Epoch 24/100
391/391 - 12s - loss: 0.1048 - accuracy: 0.9636 - val_loss: 1.1065 - val_accuracy: 0.7578
Epoch 25/100
391/391 - 12s - loss: 0.0982 - accuracy: 0.9665 - val_loss: 1.0363 - val_accuracy: 0.7739
Epoch 26/100
391/391 - 12s - loss: 0.0981 - accuracy: 0.9654 - val_loss: 0.9808 - val_accuracy: 0.7751
Epoch 27/100
391/391 - 12s - loss: 0.0975 - accuracy: 0.9660 - val_loss: 0.9447 - val_accuracy: 0.7792
Epoch 28/100
391/391 - 12s - loss: 0.0841 - accuracy: 0.9718 - val_loss: 1.0888 - val_accuracy: 0.7682
Epoch 29/100
391/391 - 12s - loss: 0.0870 - accuracy: 0.9703 - val_loss: 1.1989 - val_accuracy: 0.7608
Epoch 30/100
391/391 - 12s - loss: 0.0790 - accuracy: 0.9720 - val_loss: 1.1056 - val_accuracy: 0.7757
Epoch 31/100
391/391 - 12s - loss: 0.0771 - accuracy: 0.9737 - val_loss: 1.0584 - val_accuracy: 0.7740
Epoch 32/100
391/391 - 12s - loss: 0.0772 - accuracy: 0.9726 - val_loss: 1.0627 - val_accuracy: 0.7794
Epoch 33/100
391/391 - 12s - loss: 0.0744 - accuracy: 0.9742 - val_loss: 1.0937 - val_accuracy: 0.7701
Epoch 34/100
391/391 - 12s - loss: 0.0697 - accuracy: 0.9759 - val_loss: 1.1701 - val_accuracy: 0.7608
Epoch 35/100
391/391 - 12s - loss: 0.0694 - accuracy: 0.9759 - val_loss: 1.0154 - val_accuracy: 0.7734
Epoch 36/100
391/391 - 12s - loss: 0.0643 - accuracy: 0.9780 - val_loss: 1.0917 - val_accuracy: 0.7651
Epoch 37/100
391/391 - 12s - loss: 0.0670 - accuracy: 0.9766 - val_loss: 1.0128 - val_accuracy: 0.7793
Epoch 38/100
391/391 - 12s - loss: 0.0589 - accuracy: 0.9801 - val_loss: 1.1592 - val_accuracy: 0.7747
Epoch 39/100
391/391 - 12s - loss: 0.0609 - accuracy: 0.9783 - val_loss: 1.0453 - val_accuracy: 0.7784
Epoch 40/100
391/391 - 12s - loss: 0.0559 - accuracy: 0.9813 - val_loss: 1.0729 - val_accuracy: 0.7849
Epoch 41/100
391/391 - 12s - loss: 0.0501 - accuracy: 0.9829 - val_loss: 1.0458 - val_accuracy: 0.7840
Epoch 42/100
391/391 - 12s - loss: 0.0575 - accuracy: 0.9807 - val_loss: 1.0665 - val_accuracy: 0.7778
Epoch 43/100
391/391 - 12s - loss: 0.0506 - accuracy: 0.9821 - val_loss: 1.2102 - val_accuracy: 0.7720
Epoch 44/100
391/391 - 12s - loss: 0.0594 - accuracy: 0.9790 - val_loss: 1.0682 - val_accuracy: 0.7762
Epoch 45/100
391/391 - 12s - loss: 0.0460 - accuracy: 0.9846 - val_loss: 1.1715 - val_accuracy: 0.7827
Epoch 46/100
391/391 - 12s - loss: 0.0518 - accuracy: 0.9822 - val_loss: 1.0777 - val_accuracy: 0.7826
Epoch 47/100
391/391 - 12s - loss: 0.0447 - accuracy: 0.9845 - val_loss: 1.0480 - val_accuracy: 0.7952
Epoch 48/100
391/391 - 12s - loss: 0.0462 - accuracy: 0.9841 - val_loss: 1.1585 - val_accuracy: 0.7780
Epoch 49/100
391/391 - 12s - loss: 0.0485 - accuracy: 0.9834 - val_loss: 1.1645 - val_accuracy: 0.7783
Epoch 50/100
391/391 - 12s - loss: 0.0455 - accuracy: 0.9846 - val_loss: 1.1599 - val_accuracy: 0.7781
Epoch 51/100
391/391 - 12s - loss: 0.0419 - accuracy: 0.9852 - val_loss: 1.1437 - val_accuracy: 0.7826
Epoch 52/100
391/391 - 12s - loss: 0.0428 - accuracy: 0.9852 - val_loss: 1.2590 - val_accuracy: 0.7824
Epoch 53/100
391/391 - 12s - loss: 0.0409 - accuracy: 0.9861 - val_loss: 1.1927 - val_accuracy: 0.7671
Epoch 54/100
391/391 - 12s - loss: 0.0394 - accuracy: 0.9862 - val_loss: 1.2036 - val_accuracy: 0.7851
Epoch 55/100
391/391 - 12s - loss: 0.0387 - accuracy: 0.9873 - val_loss: 1.1172 - val_accuracy: 0.7868
Epoch 56/100
391/391 - 12s - loss: 0.0391 - accuracy: 0.9864 - val_loss: 1.0991 - val_accuracy: 0.7904
Epoch 57/100
391/391 - 12s - loss: 0.0374 - accuracy: 0.9869 - val_loss: 1.2256 - val_accuracy: 0.7818
Epoch 58/100
391/391 - 12s - loss: 0.0381 - accuracy: 0.9870 - val_loss: 1.1179 - val_accuracy: 0.7924
Epoch 59/100
391/391 - 12s - loss: 0.0344 - accuracy: 0.9887 - val_loss: 1.1018 - val_accuracy: 0.7911
Epoch 60/100
391/391 - 12s - loss: 0.0371 - accuracy: 0.9869 - val_loss: 1.1696 - val_accuracy: 0.7869
Epoch 61/100
391/391 - 12s - loss: 0.0359 - accuracy: 0.9875 - val_loss: 1.1475 - val_accuracy: 0.7877
Epoch 62/100
391/391 - 12s - loss: 0.0349 - accuracy: 0.9881 - val_loss: 1.1131 - val_accuracy: 0.7915
Epoch 63/100
391/391 - 12s - loss: 0.0367 - accuracy: 0.9875 - val_loss: 1.1281 - val_accuracy: 0.7935
Epoch 64/100
391/391 - 12s - loss: 0.0302 - accuracy: 0.9898 - val_loss: 1.2141 - val_accuracy: 0.7843
Epoch 65/100
391/391 - 12s - loss: 0.0343 - accuracy: 0.9882 - val_loss: 1.1785 - val_accuracy: 0.7882
Epoch 66/100
391/391 - 12s - loss: 0.0305 - accuracy: 0.9896 - val_loss: 1.1479 - val_accuracy: 0.7888
Epoch 67/100
391/391 - 12s - loss: 0.0308 - accuracy: 0.9891 - val_loss: 1.1175 - val_accuracy: 0.7971
Epoch 68/100
391/391 - 12s - loss: 0.0287 - accuracy: 0.9904 - val_loss: 1.1086 - val_accuracy: 0.7896
Epoch 69/100
391/391 - 12s - loss: 0.0288 - accuracy: 0.9902 - val_loss: 1.2120 - val_accuracy: 0.7912
Epoch 70/100
391/391 - 12s - loss: 0.0304 - accuracy: 0.9896 - val_loss: 1.2111 - val_accuracy: 0.7888
Epoch 71/100
391/391 - 12s - loss: 0.0320 - accuracy: 0.9890 - val_loss: 1.1830 - val_accuracy: 0.7944
Epoch 72/100
391/391 - 12s - loss: 0.0269 - accuracy: 0.9909 - val_loss: 1.3520 - val_accuracy: 0.7860
Epoch 73/100
391/391 - 12s - loss: 0.0297 - accuracy: 0.9895 - val_loss: 1.2121 - val_accuracy: 0.7915
Epoch 74/100
391/391 - 12s - loss: 0.0277 - accuracy: 0.9903 - val_loss: 1.2164 - val_accuracy: 0.7951
Epoch 75/100
391/391 - 12s - loss: 0.0261 - accuracy: 0.9910 - val_loss: 1.1703 - val_accuracy: 0.7924
Epoch 76/100
391/391 - 12s - loss: 0.0280 - accuracy: 0.9906 - val_loss: 1.1571 - val_accuracy: 0.7917
Epoch 77/100
391/391 - 12s - loss: 0.0256 - accuracy: 0.9911 - val_loss: 1.1671 - val_accuracy: 0.7921
Epoch 78/100
391/391 - 12s - loss: 0.0264 - accuracy: 0.9909 - val_loss: 1.2352 - val_accuracy: 0.7847
Epoch 79/100
391/391 - 12s - loss: 0.0285 - accuracy: 0.9900 - val_loss: 1.1431 - val_accuracy: 0.7996
Epoch 80/100
391/391 - 12s - loss: 0.0237 - accuracy: 0.9921 - val_loss: 1.2231 - val_accuracy: 0.7899
Epoch 81/100
391/391 - 12s - loss: 0.0213 - accuracy: 0.9928 - val_loss: 1.2357 - val_accuracy: 0.7840
Epoch 82/100
391/391 - 12s - loss: 0.0268 - accuracy: 0.9907 - val_loss: 1.2162 - val_accuracy: 0.7951
Epoch 83/100
391/391 - 12s - loss: 0.0262 - accuracy: 0.9908 - val_loss: 1.1731 - val_accuracy: 0.7870
Epoch 84/100
391/391 - 12s - loss: 0.0236 - accuracy: 0.9919 - val_loss: 1.1596 - val_accuracy: 0.7951
Epoch 85/100
391/391 - 12s - loss: 0.0213 - accuracy: 0.9928 - val_loss: 1.1792 - val_accuracy: 0.7922
Epoch 86/100
391/391 - 12s - loss: 0.0254 - accuracy: 0.9914 - val_loss: 1.2186 - val_accuracy: 0.7946
Epoch 87/100
391/391 - 12s - loss: 0.0204 - accuracy: 0.9928 - val_loss: 1.2262 - val_accuracy: 0.7924
Epoch 88/100
391/391 - 12s - loss: 0.0237 - accuracy: 0.9918 - val_loss: 1.2078 - val_accuracy: 0.7935
Epoch 89/100
391/391 - 12s - loss: 0.0250 - accuracy: 0.9916 - val_loss: 1.2620 - val_accuracy: 0.7854
Epoch 90/100
391/391 - 12s - loss: 0.0253 - accuracy: 0.9916 - val_loss: 1.2176 - val_accuracy: 0.7954
Epoch 91/100
391/391 - 12s - loss: 0.0207 - accuracy: 0.9927 - val_loss: 1.2793 - val_accuracy: 0.7965
Epoch 92/100
391/391 - 12s - loss: 0.0188 - accuracy: 0.9937 - val_loss: 1.2463 - val_accuracy: 0.7965
Epoch 93/100
391/391 - 12s - loss: 0.0216 - accuracy: 0.9924 - val_loss: 1.1830 - val_accuracy: 0.7969
Epoch 94/100
391/391 - 12s - loss: 0.0208 - accuracy: 0.9926 - val_loss: 1.2837 - val_accuracy: 0.7873
Epoch 95/100
391/391 - 12s - loss: 0.0224 - accuracy: 0.9922 - val_loss: 1.1855 - val_accuracy: 0.7967
Epoch 96/100
391/391 - 12s - loss: 0.0213 - accuracy: 0.9926 - val_loss: 1.2020 - val_accuracy: 0.7991
Epoch 97/100
391/391 - 12s - loss: 0.0207 - accuracy: 0.9928 - val_loss: 1.2788 - val_accuracy: 0.7882
Epoch 98/100
391/391 - 12s - loss: 0.0159 - accuracy: 0.9950 - val_loss: 1.3657 - val_accuracy: 0.7834
Epoch 99/100
391/391 - 12s - loss: 0.0208 - accuracy: 0.9929 - val_loss: 1.1962 - val_accuracy: 0.7996
Epoch 100/100
391/391 - 12s - loss: 0.0211 - accuracy: 0.9930 - val_loss: 1.2275 - val_accuracy: 0.7941
INFO: Training Time: 1186.733 seconds
79/79 - 1s - loss: 1.2275 - accuracy: 0.7941
INFO: Test Loss: 1.2274587154388428
INFO: Test Accuracy: 0.7940999865531921
