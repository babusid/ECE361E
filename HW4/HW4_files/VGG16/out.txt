Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv0 (Conv2D)               (None, 32, 32, 64)        1792      
_________________________________________________________________
activation (Activation)      (None, 32, 32, 64)        0         
_________________________________________________________________
conv1 (Conv2D)               (None, 32, 32, 64)        36928     
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 16, 16, 64)        0         
_________________________________________________________________
conv3 (Conv2D)               (None, 16, 16, 128)       73856     
_________________________________________________________________
activation_2 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
conv4 (Conv2D)               (None, 16, 16, 128)       147584    
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
pool5 (MaxPooling2D)         (None, 8, 8, 128)         0         
_________________________________________________________________
conv6 (Conv2D)               (None, 8, 8, 256)         295168    
_________________________________________________________________
activation_4 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
conv7 (Conv2D)               (None, 8, 8, 256)         590080    
_________________________________________________________________
activation_5 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
pool8 (MaxPooling2D)         (None, 4, 4, 256)         0         
_________________________________________________________________
conv9 (Conv2D)               (None, 4, 4, 512)         1180160   
_________________________________________________________________
activation_6 (Activation)    (None, 4, 4, 512)         0         
_________________________________________________________________
conv10 (Conv2D)              (None, 4, 4, 512)         2359808   
_________________________________________________________________
activation_7 (Activation)    (None, 4, 4, 512)         0         
_________________________________________________________________
conv11 (Conv2D)              (None, 4, 4, 512)         2359808   
_________________________________________________________________
activation_8 (Activation)    (None, 4, 4, 512)         0         
_________________________________________________________________
pool12 (MaxPooling2D)        (None, 2, 2, 512)         0         
_________________________________________________________________
conv13 (Conv2D)              (None, 2, 2, 512)         2359808   
_________________________________________________________________
activation_9 (Activation)    (None, 2, 2, 512)         0         
_________________________________________________________________
conv14 (Conv2D)              (None, 2, 2, 512)         2359808   
_________________________________________________________________
activation_10 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
conv15 (Conv2D)              (None, 2, 2, 512)         2359808   
_________________________________________________________________
activation_11 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
pool16 (MaxPooling2D)        (None, 1, 1, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
dense1 (Dense)               (None, 512)               262656    
_________________________________________________________________
activation_12 (Activation)   (None, 512)               0         
_________________________________________________________________
dense2 (Dense)               (None, 512)               262656    
_________________________________________________________________
activation_13 (Activation)   (None, 512)               0         
_________________________________________________________________
dense3 (Dense)               (None, 10)                5130      
_________________________________________________________________
activation_14 (Activation)   (None, 10)                0         
=================================================================
Total params: 14,655,050
Trainable params: 14,655,050
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
391/391 - 24s - loss: 2.3028 - accuracy: 0.0990
Epoch 2/100
391/391 - 11s - loss: 2.3028 - accuracy: 0.0971
Epoch 3/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0962
Epoch 4/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0989
Epoch 5/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0966
Epoch 6/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0973
Epoch 7/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0985
Epoch 8/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0984
Epoch 9/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0981
Epoch 10/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0995
Epoch 11/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0968
Epoch 12/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0987
Epoch 13/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0996
Epoch 14/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0991
Epoch 15/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0993
Epoch 16/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0970
Epoch 17/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0963
Epoch 18/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0977
Epoch 19/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0977
Epoch 20/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0976
Epoch 21/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0973
Epoch 22/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.1004
Epoch 23/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0986
Epoch 24/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 25/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0972
Epoch 26/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0983
Epoch 27/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0948
Epoch 28/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0969
Epoch 29/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0993
Epoch 30/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0977
Epoch 31/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0956
Epoch 32/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0986
Epoch 33/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0997
Epoch 34/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 35/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0986
Epoch 36/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0992
Epoch 37/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0974
Epoch 38/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 39/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0984
Epoch 40/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 41/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0996
Epoch 42/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0991
Epoch 43/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0992
Epoch 44/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0999
Epoch 45/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0981
Epoch 46/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0982
Epoch 47/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0998
Epoch 48/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0977
Epoch 49/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 50/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0969
Epoch 51/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0996
Epoch 52/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 53/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0978
Epoch 54/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0985
Epoch 55/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 56/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0991
Epoch 57/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 58/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0973
Epoch 59/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 60/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0978
Epoch 61/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0962
Epoch 62/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0981
Epoch 63/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 64/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0968
Epoch 65/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0984
Epoch 66/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0959
Epoch 67/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 68/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0981
Epoch 69/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0974
Epoch 70/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0973
Epoch 71/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0979
Epoch 72/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0969
Epoch 73/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0982
Epoch 74/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0993
Epoch 75/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0984
Epoch 76/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0997
Epoch 77/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0987
Epoch 78/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0993
Epoch 79/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0966
Epoch 80/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0985
Epoch 81/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0983
Epoch 82/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0984
Epoch 83/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 84/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0973
Epoch 85/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0993
Epoch 86/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0978
Epoch 87/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0984
Epoch 88/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0980
Epoch 89/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0979
Epoch 90/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0957
Epoch 91/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 92/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0982
Epoch 93/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0972
Epoch 94/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0995
Epoch 95/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0994
Epoch 96/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0979
Epoch 97/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0975
Epoch 98/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0988
Epoch 99/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0990
Epoch 100/100
391/391 - 11s - loss: 2.3027 - accuracy: 0.0985
INFO: Training Time: 1123.050 seconds
79/79 - 1s - loss: 2.3026 - accuracy: 0.1000
INFO: Test Loss: 2.3025975227355957
INFO: Test Accuracy: 0.10000000149011612
